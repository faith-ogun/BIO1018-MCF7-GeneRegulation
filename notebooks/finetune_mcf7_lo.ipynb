{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Finetune a GET Model on MCF-7 Bulk Data (Leaving out chr1, on a uniform cell line)\n",
    "\n",
    "\n",
    " This tutorial demonstrates how to train a GET model to predict expression in ATAC-seq peaks using motif information. We'll cover:\n",
    "\n",
    " 1. Loading and configuring the model\n",
    "\n",
    " 2. Finetune from a pretrained expression prediction GET model\n",
    "\n",
    " 3. Perform various analysis using `gcell` package\n",
    "\n",
    "\n",
    "\n",
    " ## Setup\n",
    "\n",
    " First, let's import the necessary modules and set up our configuration.\n",
    " \n",
    " Note:\n",
    " If you run from a Mac, make sure you use the jupyter notebook rather than the VSCode interactive python editor as the later seems to have issue with multiple workers.\n",
    " If you run from Linux, both should work fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from gcell.cell.celltype import GETHydraCellType\n",
    "\n",
    "from get_model.config.config import load_config\n",
    "from get_model.run_region import run_zarr as run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Finetune Run 1\n",
    "\n",
    "\n",
    "\n",
    " We'll start by loading a predefined configuration and customizing it for our needs.\n",
    "\n",
    " The base configuration is in `get_model/config/finetune_tutorial_pbmc.yaml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: In the paper, we mainly used binary ATAC signal trained model for motif interpretation analysis. As it's hard to say whether there are mutual causal relationship between transcription and accessibility. If accessibility is added to the model, potentially it will absorb some TF's effect to itself, thereby making the interpretation more difficult. However, if the goal is to represent the cell states as precisely as possible and use the model for other downstream tasks (e.g. enhancer target prediction), adding the accessibility signal is probably better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config('finetune_tutorial_pbmc') # load the predefined finetune tutorial config\n",
    "cfg.stage = 'fit'\n",
    "cfg.run.run_name = 'training_from_finetune_lora_chr1_split_QATAC'\n",
    "cfg.dataset.quantitative_atac = True # We use binary ATAC signal for motif interpretation analysis\n",
    "\n",
    "cfg.dataset.zarr_path = \"/project/home/p200469/get_BIO1018/get_preprocess_output.zarr/\"\n",
    "cfg.dataset.celltypes = \"all_chrs\"\n",
    "\n",
    "# Set a unique project name for training on all chromosomes\n",
    "cfg.run.project_name = 'finetune_all_chrs'\n",
    "cfg.dataset.celltypes = \"all_chrs\"\n",
    "cfg.finetune.checkpoint = \"./checkpoint-best.pth\" # set the path to the pretrained checkpoint we want to finetune from\n",
    "cfg.dataset.leave_out_celltypes = '' # set the celltypes you want to leave out, '' here means no celltype leave out\n",
    "cfg.dataset.leave_out_chromosomes = 'chr1' # set the chromosomes you want to leave out, '' here means no chromosome leave out\n",
    "cfg.machine.num_devices=0 # use 0 for cpu training; >=1 for gpu training\n",
    "cfg.machine.batch_size=8 # batch size for training; check `nvidia-smi` to see the available GPU memory\n",
    "\n",
    "cfg.machine.output_dir = \"/project/home/p200469/get_BIO1018/get_ML_output\"\n",
    "cfg.training.epochs = 50\n",
    "\n",
    "cfg.training.val_check_interval = 5.0 \n",
    "\n",
    "print(f\"output path: {cfg.machine.output_dir}/{cfg.run.project_name}/{cfg.run.run_name}\")\n",
    "print(f\"training for {cfg.training.epochs} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start the finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!curl -O https://2023-get-xf2217.s3.amazonaws.com/get_demo/checkpoints/regulatory_inference_checkpoint_fetal_adult/finetune_fetal_adult_leaveout_astrocyte/checkpoint-best.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = run(cfg) # run the finetuning, takes around 2 hours on one RTX 3090\n",
    "cfg.finetune.checkpoint = \"./checkpoint-best.pth\"\n",
    "print(\"checkpoint path:\", trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation\n",
    "\n",
    "After finetuning, we can use the checkpoint to predict expression of all accessible genes and generate jacobian matrix of (peak x motif) for every predicted genes. \n",
    "To start, we need to collect the checkpoint we produced and switch to `predict` stage. Here, let's focus on CD4 Naive cell and we need to set `cfg.leave_out_celltypes` to `cd4_naive` for the model to predict gene expression in this cell type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_checkpoint = '/project/home/p200469/get_BIO1018/get_ML_output/finetune_all_chrs/training_from_finetune_lora_chr1_split_QATAC/checkpoints/best.ckpt'\n",
    "cfg.stage = 'predict'\n",
    "cfg.finetune.resume_ckpt = use_checkpoint\n",
    "\n",
    "cfg.dataset.celltypes = \"all_chrs\"\n",
    "\n",
    "cfg.run.use_wandb = False # disable wandb logging when predicting\n",
    "cfg.task.layer_names = [] # set to empty list to disable intermediate layer interpretation\n",
    "cfg.task.gene_list = None # set to None to predict all genes; otherwise you can specify a list of genes as 'MYC,SOX10,SOX2,RET', only genes with promoter open will be used\n",
    "# loop through all celltypes and run the predict stage\n",
    "cfg.run.run_name='interpret_training_from_finetune_lora_chr1_split_QATAC'\n",
    "\n",
    "cfg.dataset.leave_out_celltypes = ''\n",
    "trainer = run(cfg)\n",
    "\n",
    "# Pearson 0.896\n",
    "# R^2 0.793\n",
    "# Spearman 0.803"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the results is now saved to `finetune_pbmc10k_multiome/interpret_training_from_finetune_lora_cd4_tcm_no_chr_split/cd4_naive.zarr`. Now we can use the `GETHydraCellType` class from `gcell` to load it.\n",
    "\n",
    "### Load interpretation result as `GETHydraCellType`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset celltype to \"all_chrs\"\n",
    "cfg.dataset.celltypes = \"all_chrs\"\n",
    "\n",
    "# Load the configuration\n",
    "cfg = load_config('finetune_tutorial_pbmc')\n",
    "\n",
    "# Update the run name\n",
    "cfg.run.run_name = 'interpret_training_from_finetune_lora_all_chrs_QATAC'\n",
    "\n",
    "# Create a gene annotation dictionary\n",
    "gene_annot_dict = {}\n",
    "\n",
    "try:\n",
    "    # Since celltypes is \"all_chrs\", set `leave_out_celltypes` to None\n",
    "    cfg.dataset.leave_out_celltypes = None\n",
    "    \n",
    "    # Load data for all chromosomes\n",
    "    hydra_celltype = GETHydraCellType.from_config(cfg, celltype=\"all_chrs\")\n",
    "    \n",
    "    # Save the gene annotations for \"all_chrs\"\n",
    "    gene_annot_dict[\"all_chrs\"] = hydra_celltype.gene_annot\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading all_chrs: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all genes in \"all_chrs\", collect the predicted and observed expression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    # Get the common intersected gene list for \"all_chrs\"\n",
    "    common_gene_list = set(gene_annot_dict[\"all_chrs\"].index)\n",
    "    \n",
    "    # Collect the expression for the common gene list\n",
    "    gene_annot_dict[\"all_chrs\"] = gene_annot_dict[\"all_chrs\"].loc[np.array(common_gene_list)]\n",
    "    \n",
    "    # Convert the gene annotations into a DataFrame for easier manipulation and visualization\n",
    "    gene_expression_df = pd.DataFrame(gene_annot_dict[\"all_chrs\"])\n",
    "    \n",
    "    print(\"Successfully collected gene expressions for all_chrs.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error processing gene annotations for all_chrs: {e}\")\n",
    "\n",
    "gene_annot_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for \"all_chrs\" excluding genes from chr1\n",
    "df = gene_annot_dict[\"all_chrs\"] \\\n",
    "    .query('Chromosome == \"chr1\"') \\\n",
    "    .reset_index()[['obs', 'pred', 'gene_name']] \\\n",
    "    .groupby('gene_name').mean().reset_index()\n",
    "\n",
    "# Pivot the DataFrame to create columns for 'pred' and 'obs'\n",
    "df_pred = df.pivot(index='gene_name', values='pred').dropna()\n",
    "df_obs = df.pivot(index='gene_name', values='obs').dropna()\n",
    "\n",
    "# Calculate the correlation between predicted and observed expression for each gene\n",
    "corrs = []\n",
    "for gene in df_pred.index:\n",
    "    try:\n",
    "        corr = df_pred.loc[gene].corr(df_obs.loc[gene])\n",
    "        corrs.append((corr, df_pred.loc[gene].mean(), df_obs.loc[gene].mean(), gene))\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating correlation for {gene}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Create a DataFrame to store correlations\n",
    "df_corr = pd.DataFrame(corrs, columns=['corr', 'pred', 'obs', 'gene_name'])\n",
    "\n",
    "print(\"Correlation calculation completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot example genes\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(11, 5))\n",
    "df_corr['corr'].hist(bins=20, ax=ax[0])\n",
    "# add total number of genes as title\n",
    "ax[0].set_title(f'Total number of genes: {len(df_corr)}\\nshared open genes across MCF-7 \\non leave out chr1')\n",
    "ax[0].set_xlabel('Uniform Clonal Cell Correlation')\n",
    "ax[0].set_ylabel('Number of Genes')\n",
    "\n",
    "sns.kdeplot(data=df_corr, x='pred', y='corr', ax=ax[1], shade=True)\n",
    "ax[1].set_title('Predicted mean vs \\nUniform Clonal Cell Correlation')\n",
    "ax[1].set_xlabel('Predicted Expression')\n",
    "ax[1].set_ylabel('Uniform Clonal Cell Correlation')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the predicted and observed expression to see whether there is any issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
